---
title: "Publications"
author: ""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
## PubMed IDs to remove
pmid_remove <- c("28824762", "26295592", "23288288", "21516278", "18830830", 
                 "18025499", "15786672", "15779224", "15322224", "30039500", 
                 "31925006", "31974356", "33877351")

## PubMed IDs to add
pmid_add <- c("33290556", "11743205", "15761153", "23857251", "26493315", 
              "30002819", "30356428", "31178352", "31857895", "18772890",
              "18573797", "33300035", "33349709")

## bioRxiv dois
## This link could be helpful in isolating just our preprints:
## https://www.biorxiv.org/search/author1%3Arobinson%2Bmd%20numresults%3A100%20sort%3Apublication-date%20direction%3Adescending%20format_result%3Astandard
## Should be of the format "10.1101/185744" 
## PLEASE ADD NEW ONES ON THE TOP
biorxiv_dois <- c("10.1101/2021.08.28.458012",
                  #"10.1101/2021.03.26.436976",
                  "10.1101/2021.01.27.428431",
                  "10.1101/2021.01.18.426963",
                  "10.1101/2020.11.24.394213",
                  "10.1101/2020.11.11.355693",
                  "10.1101/2021.11.11.467877",
                  "10.1101/2021.11.15.468676",
                  "10.1101/2021.12.08.471089",
                  "10.1101/2021.12.22.473434",
                  "10.1101/2022.03.08.483466",
                  "10.1101/2022.02.08.479579")

# peerj_dois <- c("10.7287/peerj.preprints.27885v2")
peerj_dois <- c()
#arxiv_dois <- c("1812.00661")
arxiv_dois <- c()


## github repos
pmid_github <- rbind(
  c(pmid = "27992111", github = "https://github.com/lmweber/cytometry-clustering-comparison"),
  c(pmid = "34001188", github = "https://github.com/fionarhuang/treeclimbR_article"),
  c(pmid = "29481549", github = "https://github.com/csoneson/conquer_comparison"),
  c(pmid = "26813113", github = "https://github.com/markrobinsonuzh/diff_splice_paper"),
  c(pmid = "30271584", github = "https://github.com/markrobinsonuzh/scRNAseq_clustering_comparison"),
  c(pmid = "30655364", github = "https://github.com/csoneson/annotation_problem_txabundance"),
  c(pmid = "31098416", github = "https://github.com/lmweber/diffcyt-evaluations"),
  c(pmid = "31366910", github = "https://github.com/csoneson/NativeRNAseqComplexTranscriptome"),
  c(pmid = "34273949", github = "https://github.com/supermaxiste/ARPEGGIO_paperAnalyses"),
  c(pmid = "31857895", github = "https://github.com/lmweber/HDCytoData"),
  c(pmid = "33257685", github = "https://github.com/HelenaLC/muscat-comparison"), 
  c(pmid = "33971812", github = "https://github.com/retogerber/censcyt_paper_scripts"),
  c(pmid = "33758076", github = "https://github.com/almutlue/mixing_benchmark"),
  c(pmid = "32873325", github = "https://github.com/plger/pipeComp"), 
  c(pmid = "32178699", github = "https://github.com/SimoneTiberi/BANDITS_manuscript"),
  c(pmid = "35140234", github = "https://github.com/csoneson/WagnerEMT2020"),
  c(pmid = "33608040", github = "https://github.com/schmeing/ReSeq-paper")
)



biorxiv_github <- rbind(
  #c(doi = "10.1101/2020.07.16.206193", github = "https://github.com/supermaxiste/ARPEGGIO_paperAnalyses"),
  c(doi = "10.1101/2021.08.28.458012", github = "https://github.com/wmacnair/SampleQC_paper_analyses"),
  c(doi = "10.1101/2020.07.17.209072", github = "https://github.com/schmeing/ReSeq-paper"),
  c(doi = "10.1101/2020.11.09.374447", github = "https://github.com/retogerber/censcyt_paper_scripts"),
  #c(doi = "10.1101/2021.03.26.436976", github = "https://github.com/csoneson/WagnerEMT2020"),
  c(doi = "10.1101/2020.12.11.420885", github = "https://github.com/almutlue/mixing_benchmark"),
  c(doi = "10.1101/2022.02.08.479579", github = "https://github.com/vladimirsouza/lrRNAseqBenchmark"),
  c(doi = "10.1101/2020.11.11.355693", github = "https://doi.org/10.5281/zenodo.4267898"),
  c(doi = "10.1101/2021.01.27.428431", github = "https://github.com/drighelli/SpatialExperiment"),
  c(doi = "10.1101/2021.11.15.468676", github = "https://github.com/HelenaLC/simulation-comparison"),
  c(doi = "10.12688/f1000research.73600.1", github = "https://github.com/plger/scDblFinder"),
  c(doi = "10.12688/f1000research.73493.1", github = "https://github.com/markrobinsonuzh/os_monitor"),
  c(doi = "10.1101/2020.11.24.394213", github = "https://github.com/SimoneTiberi/distinct_manuscript")
)

## data repos
pmid_data <- rbind(
  c(pmid = "27992111", data = "http://flowrepository.org/id/FR-FCM-ZZPH"),
  c(pmid = "30271584", data = "https://bioconductor.org/packages/DuoClustering2018/"),
  c(pmid = "33257685", data = "https://doi.org/10.6084/m9.figshare.8986193.v3"),
  c(pmid = "33758076", data = "https://doi.org/10.6084/m9.figshare.13341200"),
  c(pmid = "31098416", data = "http://flowrepository.org/id/FR-FCM-ZYL8")
)
biorxiv_data <- rbind(
  c(doi = "10.1101/349738", data = "http://flowrepository.org/id/FR-FCM-ZYL8"),
  c(doi = "10.1101/2021.11.15.468676", data = "https://doi.org/10.5281/zenodo.5678872"),
  c(doi = "10.1101/2022.02.08.479579", data = "https://doi.org/10.5281/zenodo.5960321"),
  c(doi = "10.1101/2020.11.11.355693", data = "https://doi.org/10.6084/m9.figshare.13221053")
)



## software packages
pmid_software <- rbind(
  c(pmid = "27027585", software = "http://bioconductor.org/packages/release/bioc/html/iCOBRA.html"),
  c(pmid = "29028961", software = "https://www.bioconductor.org/packages/countsimQC/"),
  c(pmid = "27130213", software = "http://lmweber.github.io/CrispantCal/"),
  c(pmid = "29605184", software = "http://bioconductor.org/packages/release/bioc/html/CATALYST.html"),
  c(pmid = "34273949", software = "https://github.com/supermaxiste/ARPEGGIO"),
  c(pmid = "31088905", software = "https://github.com/csoneson/ARMOR"),
  c(pmid = "31098416", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  c(pmid = "31857895", software = "http://bioconductor.org/packages/HDCytoData/"),
  c(pmid = "32487212", software = "http://bioconductor.org/packages/release/bioc/html/DAMEfinder.html"),
  c(pmid = "33257685", software = "http://bioconductor.org/packages/release/bioc/html/muscat.html"),
  c(pmid = "32873325", software = "http://bioconductor.org/packages/release/bioc/html/pipeComp.html"),
  c(pmid = "34001188", software = "https://github.com/fionarhuang/treeclimbR"),
  c(pmid = "33274053", software = "https://www.bioconductor.org/packages/release/bioc/html/TreeSummarizedExperiment.html"),
  c(pmid = "33758076", software = "https://www.bioconductor.org/packages/release/bioc/html/CellMixS.html"),
  c(pmid = "32178699", software = "http://bioconductor.org/packages/release/bioc/html/BANDITS.html"),
  c(pmid = "33971812", software = "https://bioconductor.org/packages/censcyt"),
  c(pmid = "33608040", software = "https://github.com/schmeing/ReSeq")
)
biorxiv_software <- rbind(
  c(doi = "10.1101/349738", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  c(doi = "10.1101/2021.08.28.458012", software = "https://github.com/wmacnair/SampleQC"),
  c(doi = "10.1101/2020.12.11.420885", software = "https://www.bioconductor.org/packages/release/bioc/html/CellMixS.html"),
  c(doi = "10.1101/2021.01.27.428431", software = "https://bioconductor.org/packages/SpatialExperiment"),
  c(doi = "10.1101/2022.02.08.479579", software = "https://github.com/vladimirsouza/lrRNAseqVariantCalling"),
  c(doi = "10.1101/2022.03.08.483466", software = "https://github.com/schmeing/gapless"),
  c(doi = "10.12688/f1000research.73600.1", software = "https://bioconductor.org/packages/scDblFinder"),
  c(doi = "10.12688/f1000research.73493.1", software = "http://pubassistant.ch/"),
  c(doi = "10.1101/2020.11.24.394213", software = "https://github.com/SimoneTiberi/distinct")
)





## publications not in PubMed/bioRxiv	
unlisted_publications <- data.frame(	
  title = c("RNA Sequencing Data: Hitchhiker's Guide to Expression Analysis."),	
  pubdate = c(""),	
  pubyear = c("2019"),	
  journal = c("Annual Review of Biomedical Data Science"),	
  authors = c("Van den Berge K, Hembach KM, Soneson C, Tiberi S, Clement L, Love MI, Patro R, Robinson MD"),	
  volume = c("2"),	
  issue = c(""),	
  pages = c("139-173"),	
  doi = c("10.1146/annurev-biodatasci-072018-021255"),	
  pmid = c(""),	
  elocationid = c("doi: 10.1146/annurev-biodatasci-072018-021255")	
)

## F1000Research articles awaiting peer review
# f1000_preprints <- NULL

f1000_preprints <- data.frame(
  title = c("An R-based reproducible and user-friendly preprocessing pipeline for CyTOF data",
            "Doublet identification in single-cell sequencing data using scDblFinder",
            "pubassistant.ch: consolidating publication profiles of researchers"),
  pubdate = c("Posted October 22, 2020.",
              "Posted September 28, 2021.",
              "Posted September 30, 2021."),
  pubyear = c("Preprints"),
  journal = c("F1000Research"),
  authors = c("Helena L. Crowell, StÃ©phane Chevrier, Andrea Jacobs, Sujana Sivapatham, Tumor Profiler Consortium, Bernd Bodenmiller, Mark D. Robinson",
              "Pierre-Luc Germain, Aaron Lun, Will Macnair, Mark D. Robinson",
              "Reto Gerber, Mark D. Robinson"),
  volume = c(9, 10, 10),
  issue = c(1263, 979, 989),
  pages = c(""),
  doi = c("10.12688/f1000research.26073.1",
          "10.12688/f1000research.73600.1",
          "10.12688/f1000research.73493.1"),
  pmid = c(""),
  elocationid = c("")
)


## names of members to highlight in publication list
group_members <- c("Robinson MD", "Mark D. Robinson", "Mark D Robinson", 
                   "Robinson M", "Mark Robinson", "Robinson, M. D.",
                   "Soneson C", "Charlotte Soneson", "Soneson, C.",
                   "Lindsay H", "Helen Lindsay",
                   "Tiberi S", "Simone Tiberi","Tiberi, S.",
                   "Germain P-L", "Germain PL", "Pierre-Luc Germain",
                   "Almut Luetge", "Luetge A", "Almut LÃ¼tge", "LÃ¼tge A",
                   "Joanna Zyprych-Walczak", "Zyprych-Walczak J",
                   "Weber LM", "Lukas M Weber", "Lukas M. Weber", "Weber, L. M.",
                   "Hembach K", "Katarina Hembach", "Katharina Hembach", "Hembach KM", "Hembach, K. M.",
                   "Katharina M. Hembach", "Yao Yao", "Yao Y",
                   "de Souza Vladimir", "Vladimir de Souza","Vladimir Barbosa C. de Souza",
                   "Souza VBC", "de Souza VBC","De Souza, V. B. C.",
                   "Huang R", "Ruizhu Huang", 
                   "Schmeing S", "Stephan Schmeing", 
                   "Orjuela S", "Stephany Orjuela", 
                   "Crowell HL", "Crowell H", "Helena L Crowell", "Helena L. Crowell", 
                   "Helena Crowell", "HelenaL Crowell", "Crowell, H. L.",
                   "Mallona I", "Izaskun Mallona",
                   "Reto Gerber","Gerber Reto","Gerber R",
                   "Manca P",
                   "Sonrel A", "Anthony Sonrel",
                   "Duo A", "Angelo Duo", "Duo A", "Angelo Duo",
                   "DuÃ² A", "Angelo DuÃ²",
                   "Nowicka M", "Malgorzata Nowicka",
                   "Zhou X", "Xiaobei Zhou",
                   "Dania Machlab",
                   "Nikolayeva O", 
                   "Komljenovic A",
                   "Morilla I", 
                   "Law CW", 
                   "Riebler A",
                   "Biyong B",
                   "Matthes KL",
                   "Will Macnair","Macnair, W.",
                   "Leonardo, S. X. M",
                   "Milosavljevic S", "Stefan Milosavljevic")
```


```{r load_packages, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
suppressPackageStartupMessages({
  library(dplyr)
  library(rentrez)
  library(rvest)
  library(XML)
  library(aRxiv)
  library(medrxivr)
})
```

```{r functions}
fix_null <- function(x) {
  if (is.null(x) || length(x) == 0) NA
  else x
}

make_link_button <- function(address, title) {
  sprintf(' <a href="%s" target="_blank" class="btn btn-primary">%s</a>', 
                   address, title)
}

make_link_text <- function(address, title) {
  sprintf(' <a href="%s" target="_blank"> %s</a>', address, title)
}


make_link_pmid <- function(pmid) {
  if (pmid != "") {	  
    sprintf(' <a href="%s" target="_blank"> %s</a>',
            paste0("http://www.ncbi.nlm.nih.gov/pubmed/", pmid),
            paste0("PMID ", pmid))
  } else {	
    ""	
  }	
}

make_link_altmetric <- function(doi) {
  sprintf('<div data-badge-popover="right" data-no-score="true" data-badge-type="bar" data-doi="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          doi)
}

make_link_altmetric_arxiv <- function(arxivid) {
  sprintf('<div data-badge-popover="right" data-badge-type="4" data-arxiv-id="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          arxivid)
}
```


```{r entrez1}
## Search PubMed
x <- entrez_search(db = "pubmed", term = "Robinson Mark D[au]", 
                   retmax = 1000)

## Add and remove PubMed IDs manually
x$ids <- unique(c(base::setdiff(x$ids, pmid_remove), pmid_add))
```

```{r entrez2, results = "hide"}
## Get abstracts and generate word cloud
pubmed_fetch <- entrez_fetch(db = "pubmed", id = x$ids,
                             rettype = "xml", parsed = TRUE)
abstracts = xpathApply(pubmed_fetch, '//PubmedArticle//Article', 
                       function(x) {xmlValue(xmlChildren(x)$Abstract)})
abstracts_all <- paste(unlist(abstracts), collapse = " ")

## Generate word cloud
base::source("generate_wordcloud.R")
#svg("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
svglite::svglite("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
rquery.wordcloud(x = abstracts_all, type = "text", 
                 textStemming = FALSE, min.freq = 2, lang = "english")
dev.off()
```

```{r extract}
## Extract info for summary table
summ <- entrez_summary(db = "pubmed", id = x$ids)
summ <- lapply(summ, function(w) {
  data.frame(title = fix_null(w$title), 
             pubdate = fix_null(w$pubdate),
             pubyear = fix_null(strsplit(w$pubdate, " ")[[1]][1]), 
             journal = fix_null(w$source), 
             authors = fix_null(paste(w$authors$name, collapse = ", ")),
             volume = fix_null(w$volume),
             issue = fix_null(w$issue),
             pages = fix_null(w$pages), 
             doi = fix_null(w$articleids$value[w$articleids$idtype == "doi"]),
             pmid = fix_null(w$articleids$value[w$articleids$idtype == "pubmed"]),
             elocationid = fix_null(w$elocationid),
             stringsAsFactors = FALSE)
})
## Put into data frame and arrange by year
summ <- do.call(rbind, summ) %>% dplyr::arrange(desc(pubyear))
```

```{r concat}	
## Add unlisted publications	
unlisted_publications <- 	
  unlisted_publications[, match(colnames(summ), 	
                                colnames(unlisted_publications))]	
colnames(unlisted_publications) <- colnames(summ)	
summ <- rbind(summ, unlisted_publications)	
```

```{r faff}
## Change some HTML formatting to markdown
summ$title <- sapply(summ$title, function(x) {
  x <- gsub("&lt;i&gt;|&lt;/i&gt;", "*", x)  ## <i>, </i>
  x <- gsub("&lt;u&gt;|&lt;/u&gt;", "*", x)  ## <u>, </u>
  x
})
```

```{r highlight_members}
## Highlight group members in bold
summ$authors <- gsub("HelenaL", "Helena L", summ$authors)

summ$authors <- sapply(summ$authors, function(a) {
  gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
})

## Remove mistakenly added editor as author
summ$authors <- sapply(summ$authors, function(a) {
  gsub(", Bar-Joseph Z", "", a)
})
```

```{r add_links, message = FALSE, warning = FALSE}
## Add column with links to GitHub repos
summ <- dplyr::left_join(summ, data.frame(pmid_github, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(github = replace(github, is.na(github), ""))

## Add column with links to data repos
summ <- dplyr::left_join(summ, data.frame(pmid_data, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(data = replace(data, is.na(data), ""))

## Add column with links to software packages
summ <- dplyr::left_join(summ, data.frame(pmid_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))
```

```{r}
## Add bioRxiv preprints by doi
# took Charlotte's code here to fix the lockdown from parsing biorxiv directly
# 
biorxiv <- do.call(rbind, lapply(biorxiv_dois, function(doi) {
  brx <- medrxivr::mx_api_doi(doi, server = "biorxiv", clean = TRUE) %>%
    dplyr::slice_max(node, n = 1)
  data.frame(title = brx$title,
             pubdate = paste0("Posted ", 
                              format(lubridate::ymd(brx$date), 
                                     "%B %d, %Y"), "."),
             pubyear = "Preprints",
             journal = "bioRxiv", 
             authors = brx$authors, 
             volume = "", issue = "", pages = "",
             doi = doi, pmid = "", elocationid = "",
             stringsAsFactors = FALSE)
}))
# biorxiv <- do.call(rbind, lapply(biorxiv_dois, function(doi) {
#   html <- read_html(paste0("https://doi.org/", doi))
#   title <- html_text(html_nodes(html, "#page-title"))
#   authors <- paste(unique(paste(html_text(html_nodes(html, ".nlm-given-names")), 
#                                 html_text(html_nodes(html, ".nlm-surname")))),
#                    collapse = ", ")
#   # pubdate <- html_text(html_nodes(html, ".published_time"))
#   m <- html_nodes(html, "meta")
#   df <- data.frame(name=html_attr(m,"name"),
#              content=html_attr(m,"content"), 
#              stringsAsFactors = FALSE, row.names = NULL) %>%
#     filter(name=="DC.Date")
#   pubdate <- paste0("Posted ", format(as.Date(df$content), "%B %d, %Y."))
# 
#   data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
#              journal = "bioRxiv", authors = authors, volume = "", issue = "", 
#              pages = "", doi = doi, pmid = "", elocationid = "", 
#              stringsAsFactors = FALSE)
# }))
```

```{r}
## Add PeerJ preprints by doi
peerj <- do.call(rbind, lapply(peerj_dois, function(doi) {
  html <- read_html(paste0("https://doi.org/", doi))
  title <- html_text(html_nodes(html, ".article-title"))
  authors <- paste(unique(paste(html_text(html_nodes(html, ".given-names")), 
                                html_text(html_nodes(html, ".surname")))), collapse = ", ")
  pubdate <- paste0("Posted ", 
                    format(as.Date(html_text(html_nodes(html, "time"))[1]), 
                           "%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "PeerJ", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```


```{r}
## Add PeerJ preprints by doi
arxiv <- do.call(rbind, lapply(arxiv_dois, function(doi) {
  df <- aRxiv::arxiv_search(id_list=doi)
  title <- df$title
  authors <- gsub("|", ", ", df$authors, fixed = TRUE)
  authors <- gsub(".", "", authors, fixed = TRUE)
  pubdate <- paste0("Posted ", format(as.Date(df$updated),"%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "arXiv", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```



```{r}
## Add F1000Research preprints
if (!is.null(biorxiv) && !is.null(f1000_preprints)) {
  f1000_preprints <- f1000_preprints[, match(colnames(biorxiv), 
                                             colnames(f1000_preprints))]
  colnames(f1000_preprints) <- colnames(biorxiv)
  biorxiv <- rbind(f1000_preprints, biorxiv)
} else if (!is.null(f1000_preprints)) {
  biorxiv <- f1000_preprints
}
```

```{r}
## soak list of PeerJ preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, peerj)
```

```{r}
## soak list of arXiv preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, arxiv)
```

```{r}
## soak list of researchsquare preprints into bioRxiv
# <- bind_rows(biorxiv, researchsquare)
```

```{r}
## sort the mix of preprints by date
pp_date <- gsub(".$", "", gsub("^Posted ","",biorxiv$pubdate))
pp_date <- gsub(",", "", pp_date)
pp_date <- as.Date(pp_date, format = "%B %d %Y")
biorxiv <- biorxiv[order(pp_date, decreasing = TRUE),]
```



```{r}
if (!is.null(biorxiv)) {
  ## Highlight group members in bold
  biorxiv$authors <- sapply(biorxiv$authors, function(a) {
    gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
  })
}
```



```{r add_links_preprints, message = FALSE, warning = FALSE}
if (!is.null(biorxiv)) {
  ## Add column with links to GitHub repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_github, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(github = replace(github, is.na(github), ""))
  
  ## Add column with links to data repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_data, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(data = replace(data, is.na(data), ""))
  
  ## Add column with links to software packages
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))
}
```




```{r}

k <- grepl("pii", summ$elocationid) & summ$pages == ""
summ$pages[k] <- sapply(strsplit(summ$elocationid[k], ". "), .subset2, 2)

## Split by publication year
years <- as.character(unique(summ$pubyear))
summ <- split(summ, summ$pubyear)

## write out table of publications/preprints to disk
write.table(bind_rows(summ), "publications.tsv", 
            quote=FALSE, sep="\t", row.names = FALSE)
saveRDS(bind_rows(summ), file="publications.rds")
write.table(biorxiv, "preprints.tsv", 
            quote=FALSE, sep="\t", row.names = FALSE)
saveRDS(biorxiv, file="preprints.rds")

# z <- read.table("publications.tsv", sep="\t", header = TRUE, quote="")
# z <- read.table("preprints.tsv", sep="\t", header = TRUE, quote="")

 

## Generate final text string to display
txt <- "<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>\n\n"



## Preprints
if (!is.null(biorxiv)) {
  txt <- paste0(txt, "\n## Preprints\n\n")
  for (j in seq_len(nrow(biorxiv))) {
    if (biorxiv[j, "journal"] == "arXiv") {
      txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " ID:", make_link_text(address = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"]), 
                                         title = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  make_link_altmetric_arxiv(biorxiv[j, "doi"]),
                  "\n\n")
    } else {
    txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " doi:", make_link_text(address = paste0("https://doi.org/", biorxiv[j, "doi"]), 
                                          title = paste0("https://doi.org/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  make_link_altmetric(biorxiv[j, "doi"]),
                  #make_link_altmetric(paste0("https://doi.org/", biorxiv[j, "doi"])),
                  "\n\n")
    }
  }
}

## Publications
for (i in years) {
  txt <- paste0(txt, "\n## ", i, "\n\n")
  for (j in seq_len(nrow(summ[[i]]))) {
    txt <- paste0(txt, "- ", summ[[i]][j, "authors"], ": ", summ[[i]][j, "title"], 
                  " ", summ[[i]][j, "journal"], " ", summ[[i]][j, "volume"],
                  ifelse(summ[[i]][j, "issue"] == "", "", 
                         paste0("(", summ[[i]][j, "issue"], ")")), ":",
                  summ[[i]][j, "pages"], 
                  #" (", i, "). DOI: ", summ[[i]][j, "doi"],
                  " (", i, "). ",
                  ifelse(!is.na(summ[[i]][j, "doi"]), 
                         paste0(make_link_text(paste0("https://doi.org/", summ[[i]][j, "doi"]),
                                        paste0("DOI: ", summ[[i]][j, "doi"])),". "),
                         ""),
                  make_link_pmid(pmid = summ[[i]][j, "pmid"]),  ifelse(summ[[i]][j, "pmid"]=="", "", ". "),  
                  #". ", make_link_pmid(pmid = summ[[i]][j, "pmid"]), ". ",  
                  ifelse(summ[[i]][j, "github"] == "", "", paste0(make_link_text(address = summ[[i]][j, "github"], 
                                                                                 title = "GitHub repo"), ". ")), 
                  ifelse(summ[[i]][j, "data"] == "", "", paste0(make_link_text(address = summ[[i]][j, "data"], 
                                                                               title = "Data"), ". ")), 
                  ifelse(summ[[i]][j, "software"] == "", "", paste0(make_link_text(address = summ[[i]][j, "software"], 
                                                                                   title = "Software"), ". ")), 
                  make_link_altmetric(paste0("https://doi.org/", summ[[i]][j, "doi"])),
                  "\n\n")
  }
}
```

```{r, results = "asis"}
cat(txt)
```

