---
title: "Publications"
author: ""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
## PubMed IDs to remove
pmid_remove <- c("28824762", "26295592", "23288288", "21516278", "18830830", 
                 "18025499", "15786672", "15779224", "15322224", "30039500", 
                 "31925006", "31974356", "33877351", "35346028", "29967347",
                 "37090609", "37645841")

## PubMed IDs to add
pmid_add <- c("33290556", "11743205", "15761153", "23857251", "26493315", 
              "30002819", "30356428", "31178352", "31857895", "18772890",
              "18573797", "33300035", "33349709", "35354817", "35482478",
              "36765378", "36495456")

## bioRxiv dois
## This link could be helpful in isolating just our preprints:
## https://www.biorxiv.org/search/author1%3Arobinson%2Bmd%20numresults%3A100%20sort%3Apublication-date%20direction%3Adescending%20format_result%3Astandard
## Should be of the format "10.1101/185744" 
biorxiv_dois <- c("10.1101/2021.11.11.467877",
                  "10.1101/2022.04.06.487263",
                  "10.1101/2023.04.12.536513",
                  "10.1101/2022.04.14.488419",
                  "10.1101/2022.06.01.493823",
                  "10.1101/2023.08.04.552046",
                  "10.1101/2023.08.17.553679",
                  "10.1101/2024.02.11.579707")

# peerj_dois <- c("10.7287/peerj.preprints.27885v2")
peerj_dois <- c()
arxiv_dois <- c("2401.02965")
#arxiv_dois <- c()


## github repos
pmid_github <- rbind(
  c(pmid = "27992111", github = "https://github.com/lmweber/cytometry-clustering-comparison"),
  c(pmid = "34001188", github = "https://github.com/fionarhuang/treeclimbR_article"),
  c(pmid = "29481549", github = "https://github.com/csoneson/conquer_comparison"),
  c(pmid = "36765378", github = "https://github.com/wmacnair/SampleQC_paper_analyses"),
  c(pmid = "26813113", github = "https://github.com/markrobinsonuzh/diff_splice_paper"),
  c(pmid = "30271584", github = "https://github.com/markrobinsonuzh/scRNAseq_clustering_comparison"),
  c(pmid = "30655364", github = "https://github.com/csoneson/annotation_problem_txabundance"),
  c(pmid = "31098416", github = "https://github.com/lmweber/diffcyt-evaluations"),
  c(pmid = "31366910", github = "https://github.com/csoneson/NativeRNAseqComplexTranscriptome"),
  c(pmid = "34273949", github = "https://github.com/supermaxiste/ARPEGGIO_paperAnalyses"),
  c(pmid = "31857895", github = "https://github.com/lmweber/HDCytoData"),
  c(pmid = "36991470", github = "https://github.com/HelenaLC/simulation-comparison"),
  c(pmid = "33257685", github = "https://github.com/HelenaLC/muscat-comparison"), 
  c(pmid = "33971812", github = "https://github.com/retogerber/censcyt_paper_scripts"),
  c(pmid = "33758076", github = "https://github.com/almutlue/mixing_benchmark"),
  c(pmid = "37095564", github = "https://github.com/vladimirsouza/lrRNAseqBenchmark"),
  c(pmid = "32873325", github = "https://github.com/plger/pipeComp"), 
  c(pmid = "32178699", github = "https://github.com/SimoneTiberi/BANDITS_manuscript"),
  c(pmid = "37198712", github = "https://github.com/markrobinsonuzh/sc_benchmark_metaanalysis"),
  c(pmid = "35140234", github = "https://github.com/csoneson/WagnerEMT2020"),
  c(pmid = "38243704", github = "https://github.com/peicai/DESpace_manuscript"),
  c(pmid = "35814628", github = "https://github.com/plger/scDblFinder"),
  c(pmid = "33608040", github = "https://github.com/schmeing/ReSeq-paper"),
  c(pmid = "35475034", github = "https://github.com/markrobinsonuzh/os_monitor")
)



biorxiv_github <- rbind(
  #c(doi = "10.1101/2020.07.16.206193", github = "https://github.com/supermaxiste/ARPEGGIO_paperAnalyses"),
  #c(doi = "10.1101/2021.08.28.458012", github = "https://github.com/wmacnair/SampleQC_paper_analyses"),
  c(doi = "10.1101/2020.07.17.209072", github = "https://github.com/schmeing/ReSeq-paper"),
  c(doi = "10.1101/2020.11.09.374447", github = "https://github.com/retogerber/censcyt_paper_scripts"),
  #c(doi = "10.1101/2021.03.26.436976", github = "https://github.com/csoneson/WagnerEMT2020"),
  c(doi = "10.1101/2020.12.11.420885", github = "https://github.com/almutlue/mixing_benchmark"),
  c(doi = "10.1101/2020.11.11.355693", github = "https://doi.org/10.5281/zenodo.4267898"),
  c(doi = "10.1101/2021.01.27.428431", github = "https://github.com/drighelli/SpatialExperiment"),
  c(doi = "10.1101/2022.04.06.487263", github = "https://wmacnair.gitlab.io/MS_lesions_snRNAseq/"),
  c(doi = "10.1101/2023.08.04.552046", github = "https://github.com/RoseYuan/benchmark_paper/"),
  c(doi = "10.1101/2022.04.14.488419", github = "https://github.com/MarioniLab/sagenet_paper"),
  c(doi = "10.1101/2022.06.01.493823", github = "https://retogerber.pages.uzh.ch/synovialscrnaseq/"),
  c(doi = "10.1101/2020.11.24.394213", github = "https://github.com/SimoneTiberi/distinct_manuscript")
)






## data repos
pmid_data <- rbind(
  c(pmid = "27992111", data = "http://flowrepository.org/id/FR-FCM-ZZPH"),
  c(pmid = "30271584", data = "https://bioconductor.org/packages/DuoClustering2018/"),
  c(pmid = "33257685", data = "https://doi.org/10.6084/m9.figshare.8986193.v3"),
  c(pmid = "36072920", data = "https://doi.org/10.6084/m9.figshare.c.5063984.v1"),
  c(pmid = "36991470", data = "https://doi.org/10.5281/zenodo.6980272"),
  c(pmid = "37198712", data = "https://doi.org/10.5281/zenodo.7096030"),
  c(pmid = "37095564", data = "https://doi.org/10.5281/zenodo.7777147"),
  c(pmid = "38243704", data = "https://doi.org/10.5281/zenodo.7829817"),
  c(pmid = "33758076", data = "https://doi.org/10.6084/m9.figshare.13341200"),
  c(pmid = "31098416", data = "http://flowrepository.org/id/FR-FCM-ZYL8")
)
biorxiv_data <- rbind(
  c(doi = "10.1101/349738", data = "http://flowrepository.org/id/FR-FCM-ZYL8"),
  c(doi = "10.1101/2022.02.08.479579", data = "https://doi.org/10.5281/zenodo.5960321"),
  c(doi = "10.1101/2020.11.11.355693", data = "https://doi.org/10.6084/m9.figshare.13221053")
)





## software packages
pmid_software <- rbind(
  c(pmid = "27027585", software = "http://bioconductor.org/packages/release/bioc/html/iCOBRA.html"),
  c(pmid = "29028961", software = "https://www.bioconductor.org/packages/countsimQC/"),
  c(pmid = "27130213", software = "http://lmweber.github.io/CrispantCal/"),
  c(pmid = "29605184", software = "http://bioconductor.org/packages/release/bioc/html/CATALYST.html"),
  c(pmid = "34273949", software = "https://github.com/supermaxiste/ARPEGGIO"),
  c(pmid = "31088905", software = "https://github.com/csoneson/ARMOR"),
  c(pmid = "31098416", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  c(pmid = "31857895", software = "http://bioconductor.org/packages/HDCytoData/"),
  c(pmid = "32487212", software = "http://bioconductor.org/packages/release/bioc/html/DAMEfinder.html"),
  c(pmid = "33257685", software = "http://bioconductor.org/packages/release/bioc/html/muscat.html"),
  c(pmid = "32873325", software = "http://bioconductor.org/packages/release/bioc/html/pipeComp.html"),
  c(pmid = "34001188", software = "https://github.com/fionarhuang/treeclimbR"),
  c(pmid = "33274053", software = "https://www.bioconductor.org/packages/release/bioc/html/TreeSummarizedExperiment.html"),
  c(pmid = "33758076", software = "https://www.bioconductor.org/packages/release/bioc/html/CellMixS.html"),
  c(pmid = "32178699", software = "http://bioconductor.org/packages/release/bioc/html/BANDITS.html"),
  c(pmid = "33971812", software = "https://bioconductor.org/packages/censcyt"),
  c(pmid = "35814628", software = "https://bioconductor.org/packages/scDblFinder"),
  c(pmid = "35475034", software = "http://pubassistant.ch/"),
  c(pmid = "36765378", software = "https://github.com/wmacnair/SampleQC"),
  c(pmid = "37142439", software = "https://github.com/schmeing/gapless"),
  c(pmid = "37095564", software = "https://github.com/vladimirsouza/lrRNAseqVariantCalling"),
  c(pmid = "38243704", software = "https://bioconductor.org/packages/release/bioc/html/DESpace.html"),
  c(pmid = "33608040", software = "https://github.com/schmeing/ReSeq"),
  c(pmid = "35482478", software = "https://bioconductor.org/packages/SpatialExperiment")
)

biorxiv_software <- rbind(
  c(doi = "10.1101/349738", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  #c(doi = "10.1101/2021.08.28.458012", software = "https://github.com/wmacnair/SampleQC"),
  c(doi = "10.1101/2023.08.04.552046", github = "https://github.com/RoseYuan/sc_chromatin_benchmark"),
  c(doi = "10.1101/2020.12.11.420885", software = "https://www.bioconductor.org/packages/release/bioc/html/CellMixS.html"),
  c(doi = "10.1101/2022.04.14.488419", software = "https://github.com/MarioniLab/SageNet"),
  c(doi = "10.1101/2020.11.24.394213", software = "https://github.com/SimoneTiberi/distinct")
)




## publications not in PubMed/bioRxiv	
unlisted_publications <- data.frame(	
  title = c("RNA Sequencing Data: Hitchhiker's Guide to Expression Analysis.",
            "distinct: A novel approach to differential distribution analyses"),
  pubdate = c(""),	
  pubyear = c("2019", "2023"),	
  journal = c("Annual Review of Biomedical Data Science",
              "Ann. Appl. Stat."),	
  authors = c("Van den Berge K, Hembach KM, Soneson C, Tiberi S, Clement L, Love MI, Patro R, Robinson MD",
              "Tiberi S, Crowell HL, Samartsidis P, Weber LM, Robinson MD"),	
  volume = c("2", "17"),	
  issue = c("", "2"),	
  pages = c("139-173", "1681-1700"),	
  doi = c("10.1146/annurev-biodatasci-072018-021255", "10.1214/22-AOAS1689"),	
  pmid = c(""),	
  elocationid = c("doi: 10.1146/annurev-biodatasci-072018-021255",
                  "doi: 10.1214/22-AOAS1689")	
)

## F1000Research articles awaiting peer review
f1000_preprints <- NULL

# f1000_preprints <- data.frame(
#   title = c("An R-based reproducible and user-friendly preprocessing pipeline for CyTOF data"),
#   pubdate = c("Posted August 8, 2022."),
#   pubyear = c("Preprints"),
#   journal = c("F1000Research"),
#   authors = c("Helena L. Crowell, Stéphane Chevrier, Andrea Jacobs, Sujana Sivapatham, Tumor Profiler Consortium, Bernd Bodenmiller, Mark D. Robinson"),
#   volume = c(9),
#   issue = c(1263),
#   pages = c(""),
#   doi = c("10.12688/f1000research.26073.2"),
#   pmid = c(""),
#   elocationid = c("")
# )



## names of members to highlight in publication list
group_members <- c("Robinson MD", "Mark D. Robinson", "Mark D Robinson", 
                   "Robinson M", "Mark Robinson", "Robinson, M. D.",
                   "Soneson C", "Charlotte Soneson", "Soneson, C.",
                   "Lindsay H", "Helen Lindsay",
                   "Tiberi S", "Simone Tiberi","Tiberi, S.",
                   "Germain P-L", "Germain PL", "Pierre-Luc Germain","Germain, P.-L.",
                   "Almut Luetge", "Luetge A", "Almut Lütge", "Lütge A","Luetge, A.",
                   "Joanna Zyprych-Walczak", "Zyprych-Walczak J",
                   "Weber LM", "Lukas M Weber", "Lukas M. Weber", "Weber, L. M.",
                   "Hembach K", "Katarina Hembach", "Katharina Hembach", 
                   "Hembach KM", "Hembach, K. M.","Betz, K. M.",
                   "Katharina M. Hembach", "Yao Yao", "Yao Y",
                   "de Souza Vladimir", "Vladimir de Souza","Vladimir Barbosa C. de Souza",
                   "Souza VBC", "de Souza VBC","De Souza, V. B. C.",
                   "Huang R", "Ruizhu Huang", 
                   "Schmeing S", "Stephan Schmeing", "Schmeing, S.",
                   "Orjuela S", "Stephany Orjuela", 
                   "Crowell HL", "Crowell H", "Helena L Crowell", "Helena L. Crowell",
                   "Helena Crowell", "HelenaL Crowell", "Crowell, H. L.",
                   "Mallona I", "Izaskun Mallona","Mallona Gonzalez, I.",
                   "Reto Gerber","Gerber Reto","Gerber R","Gerber, R.",
                   "Manca P",
                   "Sonrel A", "Anthony Sonrel","Sonrel, A.",
                   "Duo A", "Angelo Duo", "Duo A", "Angelo Duo",
                   "Duò A", "Angelo Duò",
                   "Nowicka M", "Malgorzata Nowicka",
                   "Zhou X", "Xiaobei Zhou",
                   "Dania Machlab",
                   "Heidari, E.", "Heidari E",
                   "Paul, D.","Sonder E","Fanaswala I","Al Ajami A",
                   "Nikolayeva O", 
                   "Komljenovic A",
                   "Morilla I", 
                   "Luo, S.","Luo S",
                   "Law CW", 
                   "Paul D",
                   "Riebler A",
                   "Biyong B",
                   "Matthes KL",
                   "Cai, P.",
                   "Will Macnair","Macnair, W.","Macnair W",
                   "Leonardo, S. X. M","Morillo Leonardo SX",
                   "Milosavljevic S", "Stefan Milosavljevic","Milosavljevic, S.")
```


```{r load_packages, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
suppressPackageStartupMessages({
  library(dplyr)
  library(rentrez)
  library(rvest)
  library(XML)
  library(aRxiv)
  library(medrxivr)
})
```

```{r functions}
fix_null <- function(x) {
  if (is.null(x) || length(x) == 0) NA
  else x
}

make_link_button <- function(address, title) {
  sprintf(' <a href="%s" target="_blank" class="btn btn-primary">%s</a>', 
                   address, title)
}

make_link_text <- function(address, title) {
  sprintf(' <a href="%s" target="_blank"> %s</a>', address, title)
}


make_link_pmid <- function(pmid) {
  if (pmid != "") {	  
    sprintf(' <a href="%s" target="_blank"> %s</a>',
            paste0("http://www.ncbi.nlm.nih.gov/pubmed/", pmid),
            paste0("PMID ", pmid))
  } else {	
    ""	
  }	
}

make_link_altmetric <- function(doi) {
  sprintf('<div data-badge-popover="right" data-no-score="true" data-badge-type="bar" data-doi="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          doi)
}

make_link_altmetric_arxiv <- function(arxivid) {
  sprintf('<div data-badge-popover="right" data-badge-type="4" data-arxiv-id="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          arxivid)
}
```


```{r entrez1}
## Search PubMed
x <- entrez_search(db = "pubmed", term = "Robinson Mark D[au]", 
                   retmax = 1000)

## Add and remove PubMed IDs manually
x$ids <- unique(c(base::setdiff(x$ids, pmid_remove), pmid_add))
```

```{r entrez2, results = "hide"}
## Get abstracts and generate word cloud
pubmed_fetch <- entrez_fetch(db = "pubmed", id = x$ids,
                             rettype = "xml", parsed = TRUE)
abstracts = xpathApply(pubmed_fetch, '//PubmedArticle//Article', 
                       function(x) {xmlValue(xmlChildren(x)$Abstract)})
abstracts_all <- paste(unlist(abstracts), collapse = " ")

## Generate word cloud
base::source("generate_wordcloud.R")
#svg("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
svglite::svglite("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
rquery.wordcloud(x = abstracts_all, type = "text", 
                 textStemming = FALSE, min.freq = 2, lang = "english")
dev.off()
```

```{r extract}
## Extract info for summary table
summ <- entrez_summary(db = "pubmed", id = x$ids)
summ <- lapply(summ, function(w) {
  data.frame(title = fix_null(w$title), 
             pubdate = fix_null(w$pubdate),
             pubyear = fix_null(strsplit(w$pubdate, " ")[[1]][1]), 
             journal = fix_null(w$source), 
             authors = fix_null(paste(w$authors$name, collapse = ", ")),
             volume = fix_null(w$volume),
             issue = fix_null(w$issue),
             pages = fix_null(w$pages), 
             doi = fix_null(w$articleids$value[w$articleids$idtype == "doi"]),
             pmid = fix_null(w$articleids$value[w$articleids$idtype == "pubmed"]),
             elocationid = fix_null(w$elocationid),
             stringsAsFactors = FALSE)
})
## Put into data frame and arrange by year
summ <- do.call(rbind, summ)

summ$pubyear[summ$pmid==35475034] <- 2022 # hack for Reto's F1000 pub (lists the wrong year)
summ$pubyear[summ$pmid==35814628] <- 2022 # hack for PL's F1000 pub (lists the wrong year)
summ$pubyear[summ$pmid==36072920] <- 2022 # hack for Helena's F1000 pub (lists the wrong year)
summ <- summ %>% dplyr::arrange(desc(pubyear))


```

```{r concat}	
## Add unlisted publications	
unlisted_publications <- 	
  unlisted_publications[, match(colnames(summ), 	
                                colnames(unlisted_publications))]	
colnames(unlisted_publications) <- colnames(summ)	
summ <- rbind(summ, unlisted_publications)	
```

```{r faff}
## Change some HTML formatting to markdown
summ$title <- sapply(summ$title, function(x) {
  x <- gsub("&lt;i&gt;|&lt;/i&gt;", "*", x)  ## <i>, </i>
  x <- gsub("&lt;u&gt;|&lt;/u&gt;", "*", x)  ## <u>, </u>
  x
})
```

```{r highlight_members}
## Highlight group members in bold
summ$authors <- gsub("HelenaL", "Helena L", summ$authors)

summ$authors <- sapply(summ$authors, function(a) {
  gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
})

## Remove mistakenly added editor as author
summ$authors <- sapply(summ$authors, function(a) {
  gsub(", Bar-Joseph Z", "", a)
})
```

```{r add_links, message = FALSE, warning = FALSE}
## Add column with links to GitHub repos
summ <- dplyr::left_join(summ, data.frame(pmid_github, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(github = replace(github, is.na(github), ""))

## Add column with links to data repos
summ <- dplyr::left_join(summ, data.frame(pmid_data, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(data = replace(data, is.na(data), ""))

## Add column with links to software packages
summ <- dplyr::left_join(summ, data.frame(pmid_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))

# hack to add software/github to Simone's AOAS paper (not in Pubmed)
summ$software[summ$doi=="10.1214/22-AOAS1689"] <- "https://bioconductor.org/packages/distinct"
summ$github[summ$doi=="10.1214/22-AOAS1689"] <- "https://github.com/SimoneTiberi/distinct_manuscript"




```

```{r}
## Add bioRxiv preprints by doi
# took Charlotte's code here to fix the lockdown from parsing biorxiv directly
# 
biorxiv <- do.call(rbind, lapply(biorxiv_dois, function(doi) {
  brx <- medrxivr::mx_api_doi(doi, server = "biorxiv", clean = TRUE) %>%
    dplyr::slice_max(node, n = 1)
  data.frame(title = brx$title,
             pubdate = paste0("Posted ", 
                              format(lubridate::ymd(brx$date), 
                                     "%B %d, %Y"), "."),
             pubyear = "Preprints",
             journal = "bioRxiv", 
             authors = brx$authors, 
             volume = "", issue = "", pages = "",
             doi = doi, pmid = "", elocationid = "",
             stringsAsFactors = FALSE)
}))
# biorxiv <- do.call(rbind, lapply(biorxiv_dois, function(doi) {
#   html <- read_html(paste0("https://doi.org/", doi))
#   title <- html_text(html_nodes(html, "#page-title"))
#   authors <- paste(unique(paste(html_text(html_nodes(html, ".nlm-given-names")), 
#                                 html_text(html_nodes(html, ".nlm-surname")))),
#                    collapse = ", ")
#   # pubdate <- html_text(html_nodes(html, ".published_time"))
#   m <- html_nodes(html, "meta")
#   df <- data.frame(name=html_attr(m,"name"),
#              content=html_attr(m,"content"), 
#              stringsAsFactors = FALSE, row.names = NULL) %>%
#     filter(name=="DC.Date")
#   pubdate <- paste0("Posted ", format(as.Date(df$content), "%B %d, %Y."))
# 
#   data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
#              journal = "bioRxiv", authors = authors, volume = "", issue = "", 
#              pages = "", doi = doi, pmid = "", elocationid = "", 
#              stringsAsFactors = FALSE)
# }))
```

```{r}
## Add PeerJ preprints by doi
peerj <- do.call(rbind, lapply(peerj_dois, function(doi) {
  html <- read_html(paste0("https://doi.org/", doi))
  title <- html_text(html_nodes(html, ".article-title"))
  authors <- paste(unique(paste(html_text(html_nodes(html, ".given-names")), 
                                html_text(html_nodes(html, ".surname")))), collapse = ", ")
  pubdate <- paste0("Posted ", 
                    format(as.Date(html_text(html_nodes(html, "time"))[1]), 
                           "%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "PeerJ", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```


```{r}
## Add PeerJ preprints by doi
arxiv <- do.call(rbind, lapply(arxiv_dois, function(doi) {
  df <- aRxiv::arxiv_search(id_list=doi)
  title <- df$title
  authors <- gsub("|", ", ", df$authors, fixed = TRUE)
  authors <- gsub(".", "", authors, fixed = TRUE)
  pubdate <- paste0("Posted ", format(as.Date(df$updated),"%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "arXiv", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```



```{r}
## Add F1000Research preprints
if (!is.null(biorxiv) && !is.null(f1000_preprints)) {
  f1000_preprints <- f1000_preprints[, match(colnames(biorxiv), 
                                             colnames(f1000_preprints))]
  colnames(f1000_preprints) <- colnames(biorxiv)
  biorxiv <- rbind(f1000_preprints, biorxiv)
} else if (!is.null(f1000_preprints)) {
  biorxiv <- f1000_preprints
}
```

```{r}
## soak list of PeerJ preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, peerj)
```

```{r}
## soak list of arXiv preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, arxiv)
```

```{r}
## soak list of researchsquare preprints into bioRxiv
# <- bind_rows(biorxiv, researchsquare)
```

```{r}
## sort the mix of preprints by date
pp_date <- gsub(".$", "", gsub("^Posted ","",biorxiv$pubdate))
pp_date <- gsub(",", "", pp_date)
pp_date <- as.Date(pp_date, format = "%B %d %Y")
biorxiv <- biorxiv[order(pp_date, decreasing = TRUE),]
```



```{r}
if (!is.null(biorxiv)) {
  ## Highlight group members in bold
  biorxiv$authors <- sapply(biorxiv$authors, function(a) {
    gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
  })
}
```



```{r add_links_preprints, message = FALSE, warning = FALSE}
if (!is.null(biorxiv)) {
  ## Add column with links to GitHub repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_github, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(github = replace(github, is.na(github), ""))
  
  ## Add column with links to data repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_data, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(data = replace(data, is.na(data), ""))
  
  ## Add column with links to software packages
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))
}
```




```{r}

k <- grepl("pii", summ$elocationid) & summ$pages == ""
summ$pages[k] <- sapply(strsplit(summ$elocationid[k], ". "), .subset2, 2)

## Split by publication year
years <- as.character(unique(summ$pubyear))
summ <- split(summ, summ$pubyear)

## write out table of publications/preprints to disk
write.table(bind_rows(summ), "publications.tsv", 
            quote=FALSE, sep="\t", row.names = FALSE)
saveRDS(bind_rows(summ), file="publications.rds")
write.table(biorxiv, "preprints.tsv", 
            quote=FALSE, sep="\t", row.names = FALSE)
saveRDS(biorxiv, file="preprints.rds")

# z <- read.table("publications.tsv", sep="\t", header = TRUE, quote="")
# z <- read.table("preprints.tsv", sep="\t", header = TRUE, quote="")

 

## Generate final text string to display
txt <- "<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>\n\n"



## Preprints
if (!is.null(biorxiv)) {
  txt <- paste0(txt, "\n## Preprints\n\n")
  for (j in seq_len(nrow(biorxiv))) {
    if (biorxiv[j, "journal"] == "arXiv") {
      txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " ID:", make_link_text(address = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"]), 
                                         title = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  #make_link_altmetric_arxiv(biorxiv[j, "doi"]),
                  "\n\n")
    } else {
    txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " doi:", make_link_text(address = paste0("https://doi.org/", biorxiv[j, "doi"]), 
                                          title = paste0("https://doi.org/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  #make_link_altmetric(biorxiv[j, "doi"]),
                  #make_link_altmetric(paste0("https://doi.org/", biorxiv[j, "doi"])),
                  "\n\n")
    }
  }
}

## Publications
for (i in years) {
  txt <- paste0(txt, "\n## ", i, "\n\n")
  for (j in seq_len(nrow(summ[[i]]))) {
    txt <- paste0(txt, "- ", summ[[i]][j, "authors"], ": ", summ[[i]][j, "title"], 
                  " ", summ[[i]][j, "journal"], " ", summ[[i]][j, "volume"],
                  ifelse(summ[[i]][j, "issue"] == "", "", 
                         paste0("(", summ[[i]][j, "issue"], ")")), ":",
                  summ[[i]][j, "pages"], 
                  #" (", i, "). DOI: ", summ[[i]][j, "doi"],
                  " (", i, "). ",
                  ifelse(!is.na(summ[[i]][j, "doi"]), 
                         paste0(make_link_text(paste0("https://doi.org/", summ[[i]][j, "doi"]),
                                        paste0("DOI: ", summ[[i]][j, "doi"])),". "),
                         ""),
                  make_link_pmid(pmid = summ[[i]][j, "pmid"]),  ifelse(summ[[i]][j, "pmid"]=="", "", ". "),  
                  #". ", make_link_pmid(pmid = summ[[i]][j, "pmid"]), ". ",  
                  ifelse(summ[[i]][j, "github"] == "", "", paste0(make_link_text(address = summ[[i]][j, "github"], 
                                                                                 title = "GitHub repo"), ". ")), 
                  ifelse(summ[[i]][j, "data"] == "", "", paste0(make_link_text(address = summ[[i]][j, "data"], 
                                                                               title = "Data"), ". ")), 
                  ifelse(summ[[i]][j, "software"] == "", "", paste0(make_link_text(address = summ[[i]][j, "software"], 
                                                                                   title = "Software"), ". ")), 
                  #make_link_altmetric(paste0("https://doi.org/", summ[[i]][j, "doi"])),
                  "\n\n")
  }
}
```

```{r, results = "asis"}
cat(txt)
```

