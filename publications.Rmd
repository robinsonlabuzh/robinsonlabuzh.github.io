---
title: "Publications"
author: ""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
## PubMed IDs to remove
pmid_remove <- c("28824762", "26295592", "23288288", "21516278", "18830830", 
                 "18025499", "15786672", "15779224", "15322224", "30039500", 
                 "31925006")

## PubMed IDs to add
pmid_add <- c("11743205", "15761153", "23857251", "26493315", 
              "30002819", "30356428", "31178352", "31857895", 
              "18772890", "18573797", "32131357")

## bioRxiv dois
## This link could be helpful in isolating just our preprints:
## https://www.biorxiv.org/search/author1%3Arobinson%2Bmd%20numresults%3A100%20sort%3Apublication-date%20direction%3Adescending%20format_result%3Astandard
## Should be of the format "10.1101/185744"
biorxiv_dois <- c("10.1101/800383","10.1101/713412", "10.1101/834242",
                  "10.1101/2020.02.02.930578")
# peerj_dois <- c("10.7287/peerj.preprints.27885v2")
peerj_dois <- c()
#arxiv_dois <- c("1812.00661")
arxiv_dois <- c()


## github repos
pmid_github <- rbind(
  c(pmid = "27992111", github = "https://github.com/lmweber/cytometry-clustering-comparison"),
  c(pmid = "29481549", github = "https://github.com/csoneson/conquer_comparison"),
  c(pmid = "26813113", github = "https://github.com/markrobinsonuzh/diff_splice_paper"),
  c(pmid = "30271584", github = "https://github.com/markrobinsonuzh/scRNAseq_clustering_comparison"),
  c(pmid = "30655364", github = "https://github.com/csoneson/annotation_problem_txabundance"),
  c(pmid = "31098416", github = "https://github.com/lmweber/diffcyt-evaluations"),
  c(pmid = "31366910", github = "https://github.com/csoneson/NativeRNAseqComplexTranscriptome"),
  c(pmid = "31857895", github = "https://github.com/lmweber/HDCytoData")
)

biorxiv_github <- rbind(
  c(doi = "10.1101/575951", github = "https://github.com/csoneson/ARMOR"),
  c(doi = "10.1101/713412", github = "https://github.com/HelenaLC/muscat-comparison"), 
  c(doi = "10.1101/750018", github = "https://github.com/SimoneTiberi/BANDITS_manuscript"), 
  c(doi = "10.1101/800383", github = "https://github.com/markrobinsonuzh/allele_specificity_paper")
)

## data repos
pmid_data <- rbind(
  c(pmid = "27992111", data = "http://flowrepository.org/id/FR-FCM-ZZPH"),
  c(pmid = "30271584", data = "https://bioconductor.org/packages/DuoClustering2018/"),
  c(pmid = "31098416", data = "http://flowrepository.org/id/FR-FCM-ZYL8")
)
biorxiv_data <- rbind(
  c(doi = "10.1101/349738", data = "http://flowrepository.org/id/FR-FCM-ZYL8"),
  c(doi = "10.1101/713412", data = "https://doi.org/10.6084/m9.figshare.8986193.v3")
)

## software packages
pmid_software <- rbind(
  c(pmid = "27027585", software = "http://bioconductor.org/packages/release/bioc/html/iCOBRA.html"),
  c(pmid = "29028961", github = "https://github.com/csoneson/countsimQC"),
  c(pmid = "27130213", software = "http://lmweber.github.io/CrispantCal/"),
  c(pmid = "29605184", software = "http://bioconductor.org/packages/release/bioc/html/CATALYST.html"),
  c(pmid = "31088905", software = "https://github.com/csoneson/ARMOR"),
  c(pmid = "31098416", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  c(pmid = "31857895", software = "http://bioconductor.org/packages/HDCytoData/")
)
biorxiv_software <- rbind(
  c(doi = "10.1101/349738", software = "https://bioconductor.org/packages/release/bioc/html/diffcyt.html"),
  c(doi = "10.1101/713412", github = "https://github.com/HelenaLC/muscat"), 
  c(doi = "10.1101/750018", github = "http://bioconductor.org/packages/release/bioc/html/BANDITS.html"), 
  c(doi = "10.1101/800383", github = "https://github.com/markrobinsonuzh/DAMEfinder")
)

## publications not in PubMed/bioRxiv	
unlisted_publications <- data.frame(	
  title = c("RNA Sequencing Data: Hitchhiker's Guide to Expression Analysis."),	
  pubdate = c(""),	
  pubyear = c("2019"),	
  journal = c("Annual Review of Biomedical Data Science"),	
  authors = c("Van den Berge K, Hembach KM, Soneson C, Tiberi S, Clement L, Love MI, Patro R, Robinson MD"),	
  volume = c("2"),	
  issue = c(""),	
  pages = c("139-173"),	
  doi = c("10.1146/annurev-biodatasci-072018-021255"),	
  pmid = c(""),	
  elocationid = c("doi: 10.1146/annurev-biodatasci-072018-021255")	
)

researchsquare <- data.frame(	
  title = "The DNA hypermethylation phenotype of colorectal cancer liver metastases resembles that of the primary colorectal cancers",	
  pubdate = "September 19, 2019",	
  pubyear = "Preprints",	
  journal = "Research Square",	
  authors = "Stephany Orjuela, Mirco Menigatti, Peter Schraml, Patrik Kambakamba, Mark D Robinson, Giancarlo Marra",
  volume = "",	
  issue = "",	
  pages = "",	
  doi = "10.21203/rs.2.15409/v1",	
  pmid = "",	
  elocationid = "doi: 10.21203/rs.2.15409/v1",
  stringsAsFactors = FALSE
)

## F1000Research articles awaiting peer review
f1000_preprints <- NULL
# f1000_preprints <- data.frame(
#   title = c("HDCytoData: Collection of high-dimensional cytometry benchmark datasets in Bioconductor object formats"),
#   pubdate = c("Posted August 19, 2019."),
#   pubyear = c("Preprints"),
#   journal = c("F1000Research"),
#   authors = c("Lukas M. Weber, Charlotte Soneson"),
#   volume = c(8),
#   issue = c(1459),
#   pages = c(""),
#   doi = c("10.12688/f1000research.20210.1"),
#   pmid = c(""),
#   elocationid = c("")
# )

## names of members to highlight in publication list
group_members <- c("Robinson MD", "Mark D. Robinson", "Mark D Robinson", 
                   "Robinson M", "Mark Robinson",
                   "Soneson C", "Charlotte Soneson",
                   "Lindsay H", "Helen Lindsay",
                   "Tiberi S", "Simone Tiberi",
                   "Germain P-L", "Germain PL", "Pierre-Luc Germain",
                   "Weber LM", "Lukas M Weber", "Lukas M. Weber", 
                   "Hembach K", "Katarina Hembach", "Katharina Hembach", "Hembach KM",
                   "Katharina M. Hembach", "Yao Yao", "Yao Y",
                   "de Souza Vladimir", "Vladimir de Souza","Vladimir Barbosa C. de Souza",
                   "Souza VBC", "de Souza VBC",
                   "Huang R", "Ruizhu Huang", 
                   "Schmeing S", "Stephan Schmeing", 
                   "Orjuela S", "Stephany Orjuela", 
                   "Crowell HL", "Crowell H", "Helena L Crowell", "Helena L. Crowell", "Helena Crowell",
                   "Mallona I", "Izaskun Mallona",
                   "Manca P",
                   "Sonrel A", "Anthony Sonrel",
                   "Duo A", "Angelo Duo", "Duo A", "Angelo Duo",
                   "Duò A", "Angelo Duò",
                   "Nowicka M", "Malgorzata Nowicka",
                   "Zhou X", "Xiaobei Zhou",
                   "Dania Machlab",
                   "Nikolayeva O", 
                   "Komljenovic A",
                   "Morilla I", 
                   "Law CW", 
                   "Riebler A",
                   "Biyong B",
                   "Matthes KL")
```


```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
suppressPackageStartupMessages({
  library(dplyr)
  library(rentrez)
  library(rvest)
  library(XML)
  library(aRxiv)
})
```

```{r}
fix_null <- function(x) {
  if (is.null(x) || length(x) == 0) NA
  else x
}

make_link_button <- function(address, title) {
  sprintf(' <a href="%s" target="_blank" class="btn btn-primary">%s</a>', 
                   address, title)
}

make_link_text <- function(address, title) {
  sprintf(' <a href="%s" target="_blank"> %s</a>', address, title)
}


make_link_pmid <- function(pmid) {
  if (pmid != "") {	  
    sprintf(' <a href="%s" target="_blank"> %s</a>',
            paste0("http://www.ncbi.nlm.nih.gov/pubmed/", pmid),
            paste0("PMID ", pmid))
  } else {	
    ""	
  }	
}

make_link_altmetric <- function(doi) {
  sprintf('<div data-badge-popover="right" data-badge-type="4" data-doi="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          doi)
}

make_link_altmetric_arxiv <- function(arxivid) {
  sprintf('<div data-badge-popover="right" data-badge-type="4" data-arxiv-id="%s" data-hide-no-mentions="true" class="altmetric-embed"></div>',
          arxivid)
}
```


```{r}
## Search PubMed
x <- entrez_search(db = "pubmed", term = "Robinson Mark D[au]", 
                   retmax = 1000)

## Add and remove PubMed IDs manually
x$ids <- unique(c(base::setdiff(x$ids, pmid_remove), pmid_add))
```

```{r, results = "hide"}
## Get abstracts and generate word cloud
pubmed_fetch <- entrez_fetch(db = "pubmed", id = x$ids,
                             rettype = "xml", parsed = TRUE)
abstracts = xpathApply(pubmed_fetch, '//PubmedArticle//Article', 
                       function(x) {xmlValue(xmlChildren(x)$Abstract)})
abstracts_all <- paste(unlist(abstracts), collapse = " ")

## Generate word cloud
base::source("generate_wordcloud.R")
#svg("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
svglite::svglite("img/abstracts_pubmed_wordcloud.svg", width = 10, height = 8)
rquery.wordcloud(x = abstracts_all, type = "text", 
                 textStemming = FALSE, min.freq = 2, lang = "english")
dev.off()
```

```{r}
## Extract info for summary table
summ <- entrez_summary(db = "pubmed", id = x$ids)
summ <- lapply(summ, function(w) {
  data.frame(title = fix_null(w$title), 
             pubdate = fix_null(w$pubdate),
             pubyear = fix_null(strsplit(w$pubdate, " ")[[1]][1]), 
             journal = fix_null(w$source), 
             authors = fix_null(paste(w$authors$name, collapse = ", ")),
             volume = fix_null(w$volume),
             issue = fix_null(w$issue),
             pages = fix_null(w$pages), 
             doi = fix_null(w$articleids$value[w$articleids$idtype == "doi"]),
             pmid = fix_null(w$articleids$value[w$articleids$idtype == "pubmed"]),
             elocationid = fix_null(w$elocationid),
             stringsAsFactors = FALSE)
})
## Put into data frame and arrange by year
summ <- do.call(rbind, summ) %>% dplyr::arrange(desc(pubyear))
```

```{r}	
## Add unlisted publications	
unlisted_publications <- 	
  unlisted_publications[, match(colnames(summ), 	
                                colnames(unlisted_publications))]	
colnames(unlisted_publications) <- colnames(summ)	
summ <- rbind(summ, unlisted_publications)	
```

```{r}
## Change some HTML formatting to markdown
summ$title <- sapply(summ$title, function(x) {
  x <- gsub("&lt;i&gt;|&lt;/i&gt;", "*", x)  ## <i>, </i>
  x <- gsub("&lt;u&gt;|&lt;/u&gt;", "*", x)  ## <u>, </u>
  x
})
```

```{r}
## Highlight group members in bold
summ$authors <- sapply(summ$authors, function(a) {
  gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
})

## Remove mistakenly added editor as author
summ$authors <- sapply(summ$authors, function(a) {
  gsub(", Bar-Joseph Z", "", a)
})
```

```{r add_links, message = FALSE, warning = FALSE}
## Add column with links to GitHub repos
summ <- dplyr::left_join(summ, data.frame(pmid_github, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(github = replace(github, is.na(github), ""))

## Add column with links to data repos
summ <- dplyr::left_join(summ, data.frame(pmid_data, stringsAsFactors = FALSE)) %>%
  dplyr::mutate(data = replace(data, is.na(data), ""))

## Add column with links to software packages
summ <- dplyr::left_join(summ, data.frame(pmid_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))
```

```{r}
## Add bioRxiv preprints by doi
biorxiv <- do.call(rbind, lapply(biorxiv_dois, function(doi) {
  html <- read_html(paste0("https://doi.org/", doi))
  title <- html_text(html_nodes(html, "#page-title"))
  authors <- paste(unique(paste(html_text(html_nodes(html, ".nlm-given-names")), 
                                html_text(html_nodes(html, ".nlm-surname")))),
                   collapse = ", ")
  # pubdate <- html_text(html_nodes(html, ".published_time"))
  m <- html_nodes(html, "meta")
  df <- data.frame(name=html_attr(m,"name"),
             content=html_attr(m,"content"), 
             stringsAsFactors = FALSE, row.names = NULL) %>%
    filter(name=="DC.Date")
  pubdate <- paste0("Posted ", format(as.Date(df$content), "%B %d, %Y."))

  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "bioRxiv", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```

```{r}
## Add PeerJ preprints by doi
peerj <- do.call(rbind, lapply(peerj_dois, function(doi) {
  html <- read_html(paste0("https://doi.org/", doi))
  title <- html_text(html_nodes(html, ".article-title"))
  authors <- paste(unique(paste(html_text(html_nodes(html, ".given-names")), 
                                html_text(html_nodes(html, ".surname")))), collapse = ", ")
  pubdate <- paste0("Posted ", 
                    format(as.Date(html_text(html_nodes(html, "time"))[1]), 
                           "%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "PeerJ", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```


```{r}
## Add PeerJ preprints by doi
arxiv <- do.call(rbind, lapply(arxiv_dois, function(doi) {
  df <- aRxiv::arxiv_search(id_list=doi)
  title <- df$title
  authors <- gsub("|", ", ", df$authors, fixed = TRUE)
  authors <- gsub(".", "", authors, fixed = TRUE)
  pubdate <- paste0("Posted ", format(as.Date(df$updated),"%B %d, %Y."))
  data.frame(title = title, pubdate = pubdate, pubyear = "Preprints", 
             journal = "arXiv", authors = authors, volume = "", issue = "", 
             pages = "", doi = doi, pmid = "", elocationid = "", 
             stringsAsFactors = FALSE)
}))
```



```{r}
## Add F1000Research preprints
if (!is.null(biorxiv) && !is.null(f1000_preprints)) {
  f1000_preprints <- f1000_preprints[, match(colnames(biorxiv), 
                                             colnames(f1000_preprints))]
  colnames(f1000_preprints) <- colnames(biorxiv)
  biorxiv <- rbind(biorxiv, f1000_preprints)
} else if (!is.null(f1000_preprints)) {
  biorxiv <- f1000_preprints
}
```

```{r}
## soak list of PeerJ preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, peerj)
```

```{r}
## soak list of arXiv preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, arxiv)
```

```{r}
## soak list of researchsquare preprints into bioRxiv
biorxiv <- bind_rows(biorxiv, researchsquare)
```


```{r}
if (!is.null(biorxiv)) {
  ## Highlight group members in bold
  biorxiv$authors <- sapply(biorxiv$authors, function(a) {
    gsub(paste0("(", paste(group_members, collapse = "|"), ")"), "<strong>\\1</strong>", a)
  })
}
```



```{r add_links_preprints, message = FALSE, warning = FALSE}
if (!is.null(biorxiv)) {
  ## Add column with links to GitHub repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_github, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(github = replace(github, is.na(github), ""))
  
  ## Add column with links to data repos
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_data, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(data = replace(data, is.na(data), ""))
  
  ## Add column with links to software packages
  biorxiv <- dplyr::left_join(biorxiv, data.frame(biorxiv_software, stringsAsFactors = FALSE)) %>%
    dplyr::mutate(software = replace(software, is.na(software), ""))
}
```




```{r}
## Split by publication year
years <- as.character(unique(summ$pubyear))
summ <- split(summ, summ$pubyear)

## Generate final text string to display
txt <- "<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>\n\n"



## Preprints
if (!is.null(biorxiv)) {
  txt <- paste0(txt, "\n## Preprints\n\n")
  for (j in seq_len(nrow(biorxiv))) {
    if (biorxiv[j, "journal"] == "arXiv") {
      txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " ID:", make_link_text(address = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"]), 
                                         title = paste0("https://arxiv.org/abs/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  make_link_altmetric_arxiv(biorxiv[j, "doi"]),
                  "\n\n")
    } else {
    txt <- paste0(txt, "- ", biorxiv[j, "authors"], ": ", biorxiv[j, "title"], 
                  ". ", biorxiv[j, "journal"], 
                  " doi:", make_link_text(address = paste0("https://doi.org/", biorxiv[j, "doi"]), title = paste0("https://doi.org/", biorxiv[j, "doi"])), ". ", 
                  biorxiv[j, "pubdate"], " ", 
                  ifelse(biorxiv[j, "github"] == "", "", paste0(make_link_text(address = biorxiv[j, "github"], 
                                                                               title = "GitHub repo"), ". ")), 
                  ifelse(biorxiv[j, "data"] == "", "", paste0(make_link_text(address = biorxiv[j, "data"], 
                                                                             title = "Data"), ". ")), 
                  ifelse(biorxiv[j, "software"] == "", "", paste0(make_link_text(address = biorxiv[j, "software"], 
                                                                                 title = "Software"), ". ")), 
                  make_link_altmetric(biorxiv[j, "doi"]),
                  #make_link_altmetric(paste0("https://doi.org/", biorxiv[j, "doi"])),
                  "\n\n")
    }
  }
}

## Publications
for (i in years) {
  txt <- paste0(txt, "\n## ", i, "\n\n")
  for (j in seq_len(nrow(summ[[i]]))) {
    txt <- paste0(txt, "- ", summ[[i]][j, "authors"], ": ", summ[[i]][j, "title"], 
                  " ", summ[[i]][j, "journal"], " ", summ[[i]][j, "volume"],
                  ifelse(summ[[i]][j, "issue"] == "", "", 
                         paste0("(", summ[[i]][j, "issue"], ")")), ":",
                  summ[[i]][j, "pages"], 
                  " (", i, "). DOI: ", summ[[i]][j, "doi"],
                  ". ", make_link_pmid(pmid = summ[[i]][j, "pmid"]),  ifelse(summ[[i]][j, "pmid"]=="", "", ". "),  
                  #". ", make_link_pmid(pmid = summ[[i]][j, "pmid"]), ". ",  
                  ifelse(summ[[i]][j, "github"] == "", "", paste0(make_link_text(address = summ[[i]][j, "github"], 
                                                                                 title = "GitHub repo"), ". ")), 
                  ifelse(summ[[i]][j, "data"] == "", "", paste0(make_link_text(address = summ[[i]][j, "data"], 
                                                                               title = "Data"), ". ")), 
                  ifelse(summ[[i]][j, "software"] == "", "", paste0(make_link_text(address = summ[[i]][j, "software"], 
                                                                                   title = "Software"), ". ")), 
                  make_link_altmetric(paste0("https://doi.org/", summ[[i]][j, "doi"])),
                  "\n\n")
  }
}
```

```{r, results = "asis"}
cat(txt)
```

